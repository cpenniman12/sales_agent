"""
Knowledge base for NVIDIA AI & Deep Learning Platforms
"""

AI_KNOWLEDGE = """
# NVIDIA AI & Deep Learning Platforms

NVIDIA provides a comprehensive AI platform, from hardware to software, frameworks, and applications, enabling organizations to build and deploy AI solutions across every industry.

## NVIDIA AI Computing

NVIDIA AI Computing combines hardware and software to accelerate the entire AI workflow, from data processing and training to inference and deployment. NVIDIA GPUs power the world's most advanced AI models, including large language models like ChatGPT and Llama.

Key Hardware:
- NVIDIA H100 Tensor Core GPU with Transformer Engine
- NVIDIA A100 Tensor Core GPU
- NVIDIA L40S GPU for versatile AI workloads
- Grace Hopper Superchip combining CPUs and GPUs

## NVIDIA AI Software

NVIDIA provides a comprehensive AI software stack that spans from frameworks and libraries to development tools and enterprise platforms.

Components:
- NVIDIA AI Enterprise: End-to-end software suite for production AI
- NVIDIA NeMo: Framework for building, customizing, and deploying generative AI
- NVIDIA RAPIDS: Libraries for data science and analytics on GPUs
- NVIDIA TensorRT: SDK for high-performance deep learning inference
- NVIDIA Triton Inference Server: Open-source inference serving software

## NVIDIA DGX Systems

NVIDIA DGX systems are purpose-built AI supercomputers designed to give data scientists the most powerful tools for AI research and development.

Product Line:
- DGX H100: The ultimate AI supercomputer with 8 H100 GPUs
- DGX A100: Enterprise AI system with 8 A100 GPUs
- DGX GH200: First system with Grace Hopper Superchips
- DGX SuperPOD: Turnkey supercomputer for enterprise AI
- DGX Cloud: AI supercomputing available as a cloud service

## Large Language Models & Generative AI

NVIDIA provides technologies and frameworks for developing, customizing, and deploying large language models (LLMs) and generative AI applications.

Key Technologies:
- NeMo Framework: Platform for building, customizing, and deploying LLMs
- NeMo Retriever: For retrieval-augmented generation (RAG) applications
- BioNeMo: For life sciences and healthcare language models
- NVIDIA AI Workbench: Unified environment for developing AI
- Microservices framework for enterprise AI deployment

## NVIDIA Transformer Engine

NVIDIA Transformer Engine is a library designed specifically to accelerate training and inference of transformer models on NVIDIA GPUs with Tensor Cores.

Features:
- 4x faster training for large language models
- 2x faster inference
- Support for FP8 precision
- Dynamic precision management
- Integration with popular AI frameworks

## Industry-Specific AI Solutions

NVIDIA offers specialized AI platforms for specific industries, including healthcare, manufacturing, retail, and financial services.

Examples:
- NVIDIA Clara for healthcare imaging and genomics
- NVIDIA Metropolis for smart cities and retail analytics
- NVIDIA Drive for autonomous vehicles
- NVIDIA Aerial for telecommunications
- NVIDIA Isaac for robotics and industrial automation

## NVIDIA AI Enterprise

NVIDIA AI Enterprise is an end-to-end, cloud-native software suite optimized to run AI workloads with enterprise support, security, and reliability.

Key Features:
- Support for VMware vSphere and cloud platforms
- NeMo framework services for generative AI
- RAPIDS for data science and analytics
- Enterprise-grade support and security
- Optimized for NVIDIA-Certified Systems
""" 